# Architecture du Module LLM

## Vue d'ensemble

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          HEISENBERG LLM MODULE                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Wakeword   â”‚â”€â”€â”€â”€â–¶â”‚     STT      â”‚â”€â”€â”€â”€â–¶â”‚     LLM      â”‚â”€â”€â”€â”€â–¶ [TTS]
â”‚  Detection   â”‚     â”‚   Whisper    â”‚     â”‚  LFM2-350M   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      IDLE              LISTENING            THINKING         SPEAKING
```

## Flux de DonnÃ©es

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER INTERACTION                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                    ğŸ¤ "Hey Jarvis, quelle heure est-il ?"
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AUDIO PIPELINE                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ 48kHzâ”‚â”€â”€â”€â–¶â”‚ RNNoise â”‚â”€â”€â”€â–¶â”‚Resample â”‚â”€â”€â”€â–¶â”‚   AGC   â”‚           â”‚
â”‚  â”‚Input â”‚    â”‚ Denoise â”‚    â”‚ to 16kHzâ”‚    â”‚Normalizeâ”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                         â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Wakeword Engine â”‚      â”‚   VAD Engine     â”‚
        â”‚  (OpenWakeWord)  â”‚      â”‚   (Silero)       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                         â”‚
                    â”‚ WAKEWORD_DETECTED       â”‚ Silence â†’ Stop
                    â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STT ENGINE (Whisper)                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Audio Buffer â†’ Whisper â†’ Transcription                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â”‚ TRANSCRIPTION_FINAL
                                 â–¼
                  "quelle heure est-il"
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SESSION MANAGER                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Conversation History:                                         â”‚  â”‚
â”‚  â”‚  Turn 1: ("qui es-tu ?", "Je suis Heisenberg")              â”‚  â”‚
â”‚  â”‚  Turn 2: ("quelle heure ?", "Il est 15h30")                 â”‚  â”‚
â”‚  â”‚  ...                                                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PROMPT BUILDER                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ System: Tu es Heisenberg, un assistant...                    â”‚  â”‚
â”‚  â”‚                                                               â”‚  â”‚
â”‚  â”‚ User: qui es-tu ?                                            â”‚  â”‚
â”‚  â”‚ Assistant: Je suis Heisenberg.                               â”‚  â”‚
â”‚  â”‚                                                               â”‚  â”‚
â”‚  â”‚ User: quelle heure est-il ?                                  â”‚  â”‚
â”‚  â”‚ Assistant:                                                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â”‚ HTTP POST (JSON)
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLAMA.CPP SERVER (localhost:8080)                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Model: LFM2-350M (GGUF)                                      â”‚  â”‚
â”‚  â”‚ Context: 2048 tokens                                         â”‚  â”‚
â”‚  â”‚ Threads: 4 CPU / GPU acceleration                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â”‚ SSE Stream
                                 â–¼
                    Token Stream: "Il" "est" "15" "h" "30"
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                         â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  LLM_TOKEN       â”‚      â”‚  LLM_COMPLETE    â”‚
        â”‚  (first token)   â”‚      â”‚  (all done)      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â–¼
                    "Il est 15h30."
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SESSION MANAGER (Update)                                           â”‚
â”‚  add_turn("quelle heure ?", "Il est 15h30.")                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   TTS ENGINE (TODO)    â”‚
                    â”‚   Text-to-Speech       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                    ğŸ”Š "Il est 15h30."
                                 â”‚
                                 â–¼
                         Back to IDLE state
```

## Composants ClÃ©s

### 1. LlamaCppLLM (`heisenberg/llm/stream.py`)

**ResponsabilitÃ©:** Client HTTP asynchrone pour llama.cpp

```python
class LlamaCppLLM(ABCLLM):
    async def generate(prompt, history) -> AsyncGenerator[str]:
        # 1. Construire le prompt avec historique
        full_prompt = prompt_builder.build(history, prompt)
        
        # 2. Envoyer requÃªte HTTP POST
        async with session.post(endpoint, json=payload):
            
            # 3. Parser SSE stream
            async for line in response.content:
                token = parse_sse(line)
                yield token  # Stream token-par-token
```

**FonctionnalitÃ©s:**
- âœ… Streaming asynchrone
- âœ… Timeouts configurables
- âœ… Callbacks (on_token, on_complete)
- âœ… Annulation gracieuse

### 2. PromptBuilder (`heisenberg/llm/prompts.py`)

**ResponsabilitÃ©:** Construction de prompts avec contexte

```python
class PromptBuilder:
    def build(history, current_query) -> str:
        # Format: System + History + Current
        prompt = f"""
        System: {system_prompt}
        
        User: {history[0][0]}
        Assistant: {history[0][1]}
        ...
        User: {current_query}
        Assistant:
        """
        return prompt
```

**Formats supportÃ©s:**
- Plain text (simple et universel)
- ChatML (`<|im_start|>...<|im_end|>`)
- Llama 2 (`[INST]...[/INST]`)

### 3. SessionManager (`heisenberg/orchestrator/session.py`)

**ResponsabilitÃ©:** Gestion de l'historique conversationnel

```python
class SessionManager:
    conversation_history: List[Tuple[str, str]]
    
    def add_turn(user_query, assistant_response):
        history.append((user_query, assistant_response))
    
    def get_history(max_turns=5) -> List[Tuple]:
        return history[-max_turns:]  # FenÃªtre glissante
```

**Avantages:**
- Contexte conversationnel
- Limite mÃ©moire (fenÃªtre glissante)
- Session persistante

### 4. IntÃ©gration FSM (`heisenberg/main.py`)

**Ã‰tats de la FSM:**

```
IDLE â”€â”€â”€â”€â”€â”€â–¶ LISTENING â”€â”€â”€â”€â”€â”€â–¶ THINKING â”€â”€â”€â”€â”€â”€â–¶ SPEAKING â”€â”€â”€â”€â”€â”€â–¶ IDLE
         (wakeword)        (transcription)    (llm_token)    (tts_complete)
```

**Ã‰vÃ©nements:**
- `WAKEWORD_DETECTED` : Mot-clÃ© dÃ©tectÃ©
- `TRANSCRIPTION_FINAL` : Phrase transcrite
- `LLM_TOKEN` : Premier token LLM
- `LLM_COMPLETE` : GÃ©nÃ©ration terminÃ©e
- `TTS_START` / `TTS_COMPLETE` : SynthÃ¨se vocale (TODO)

## Optimisations de Latence

### Pipeline Actuel

```
User parle â”€â”€â”€â”€â–¶ STT â”€â”€â”€â”€â–¶ LLM â”€â”€â”€â”€â–¶ [TTS] â”€â”€â”€â”€â–¶ Audio out
  ~2-3s          ~1-2s      ~0.5-2s     ~1-2s
  
Total: ~4-9 secondes (selon config)
```

### Optimisations Possibles

1. **Streaming TTS** (TODO)
```
LLM: "Bonjour je suis Heisenberg et..."
         â”‚         â”‚          â”‚
         â–¼         â–¼          â–¼
TTS:  [Bonjour] [je suis] [Heisenberg]...
         â”‚         â”‚          â”‚
         â–¼         â–¼          â–¼
Audio:  ğŸ”Š        ğŸ”Š         ğŸ”Š

â†’ RÃ©duction latence perÃ§ue: 50-70%
```

2. **Prompt Caching**
```
System prompt (constant) â”€â”€â”
Previous turns (cached)    â”‚â”€â”€â–¶ Cached in llama.cpp
                          â”‚
New query â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”€â”€â–¶ Only process this

â†’ RÃ©duction latence: 20-40%
```

3. **Model Quantization**
```
FP16: ~700MB, ~30 tokens/sec
Q8:   ~350MB, ~50 tokens/sec  âœ… RecommandÃ©
Q4:   ~200MB, ~80 tokens/sec  (lÃ©gÃ¨re perte qualitÃ©)
```

## Configuration AvancÃ©e

### ParamÃ¨tres de GÃ©nÃ©ration

```python
@dataclass
class LLMConfig:
    # CrÃ©ativitÃ©
    temperature: float = 0.7      # 0.0=dÃ©terministe, 1.0=crÃ©atif
    top_p: float = 0.9           # Nucleus sampling
    top_k: int = 40              # Top-K sampling
    
    # ContrÃ´le
    max_tokens: int = 512        # Longueur max rÃ©ponse
    repeat_penalty: float = 1.1  # Anti-rÃ©pÃ©tition
    
    # Performance
    timeout_seconds: int = 30
    max_history_turns: int = 5
```

### Format de Prompt

Ajustez selon votre modÃ¨le:

```python
# Pour LFM2, Mistral, etc.
format_style = "plain"

# Pour GPT-3.5/4 style
format_style = "chatml"

# Pour Llama 2
format_style = "llama2"
```

## MÃ©triques et Monitoring

### Logs Importants

```
[INFO] First LLM token received         # TTFT (Time To First Token)
[INFO] LLM generation complete. Tokens: 45  # Total tokens
[DEBUG] Sending prompt to LLM (length: 823)  # Prompt size
```

### Mesures de Performance

```python
import time

start = time.time()
async for token in llm.generate(query):
    if first_token:
        ttft = time.time() - start  # Time To First Token
        print(f"TTFT: {ttft:.2f}s")
```

## DÃ©pannage Rapide

| ProblÃ¨me | Solution |
|----------|----------|
| Connection refused | DÃ©marrer llama-server |
| Timeout | Augmenter `timeout_seconds` |
| RÃ©ponses vides | VÃ©rifier `format_style` |
| Trop lent | Utiliser model Q8/Q4, activer GPU |
| Out of memory | RÃ©duire `max_tokens`, `max_history_turns` |
| RÃ©pÃ©titions | Augmenter `repeat_penalty` |

## RÃ©fÃ©rences

- Code: `heisenberg/llm/stream.py`, `heisenberg/llm/prompts.py`
- Tests: `heisenberg/tests/test_llm.py`
- Docs: `docs/LLM_GUIDE.md`, `docs/INTEGRATION_COMPLETE.md`
- llama.cpp: https://github.com/ggerganov/llama.cpp


